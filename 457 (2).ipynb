{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "528\n",
      "('X_train shape:', (422L, 1L, 32L, 32L))\n",
      "(422L, 'train samples')\n",
      "(106L, 'test samples')\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/12\n",
      "422/422 [==============================] - 9s - loss: 1.9987 - acc: 0.4621 - val_loss: 1.4662 - val_acc: 0.6321\n",
      "Epoch 2/12\n",
      "422/422 [==============================] - 9s - loss: 1.0599 - acc: 0.6422 - val_loss: 1.0257 - val_acc: 0.6321\n",
      "Epoch 3/12\n",
      "422/422 [==============================] - 9s - loss: 1.0788 - acc: 0.5687 - val_loss: 1.0620 - val_acc: 0.6321\n",
      "Epoch 4/12\n",
      "422/422 [==============================] - 9s - loss: 0.9991 - acc: 0.6445 - val_loss: 1.0752 - val_acc: 0.6321\n",
      "Epoch 5/12\n",
      "422/422 [==============================] - 10s - loss: 1.0010 - acc: 0.6256 - val_loss: 1.3062 - val_acc: 0.6887\n",
      "Epoch 6/12\n",
      "422/422 [==============================] - 10s - loss: 1.0271 - acc: 0.5877 - val_loss: 0.9628 - val_acc: 0.6321\n",
      "Epoch 7/12\n",
      "422/422 [==============================] - 9s - loss: 0.9417 - acc: 0.6303 - val_loss: 0.9889 - val_acc: 0.6321\n",
      "Epoch 8/12\n",
      "422/422 [==============================] - 9s - loss: 0.9241 - acc: 0.6564 - val_loss: 0.9528 - val_acc: 0.6321\n",
      "Epoch 9/12\n",
      "422/422 [==============================] - 10s - loss: 0.9241 - acc: 0.6540 - val_loss: 0.9578 - val_acc: 0.6321\n",
      "Epoch 10/12\n",
      "422/422 [==============================] - 10s - loss: 0.9008 - acc: 0.6493 - val_loss: 0.9263 - val_acc: 0.6321\n",
      "Epoch 11/12\n",
      "422/422 [==============================] - 10s - loss: 0.9073 - acc: 0.6469 - val_loss: 0.9196 - val_acc: 0.6321\n",
      "Epoch 12/12\n",
      "422/422 [==============================] - 12s - loss: 0.8657 - acc: 0.6611 - val_loss: 1.0846 - val_acc: 0.6226\n",
      "Train on 422 samples, validate on 106 samples\n",
      "Epoch 1/12\n",
      "422/422 [==============================] - 12s - loss: 0.9599 - acc: 0.6066 - val_loss: 1.1493 - val_acc: 0.6226\n",
      "Epoch 2/12\n",
      "422/422 [==============================] - 9s - loss: 0.8355 - acc: 0.6209 - val_loss: 0.8162 - val_acc: 0.6321\n",
      "Epoch 3/12\n",
      "422/422 [==============================] - 11s - loss: 0.8687 - acc: 0.6777 - val_loss: 0.8538 - val_acc: 0.6887\n",
      "Epoch 4/12\n",
      "422/422 [==============================] - 13s - loss: 0.7914 - acc: 0.6635 - val_loss: 0.9464 - val_acc: 0.6132\n",
      "Epoch 5/12\n",
      "422/422 [==============================] - 10s - loss: 0.8696 - acc: 0.6540 - val_loss: 1.2019 - val_acc: 0.4811\n",
      "Epoch 6/12\n",
      "422/422 [==============================] - 11s - loss: 0.8300 - acc: 0.6137 - val_loss: 0.8258 - val_acc: 0.6887\n",
      "Epoch 7/12\n",
      "422/422 [==============================] - 11s - loss: 0.7493 - acc: 0.6825 - val_loss: 0.9303 - val_acc: 0.6226\n",
      "Epoch 8/12\n",
      "422/422 [==============================] - 14s - loss: 0.7775 - acc: 0.6825 - val_loss: 1.0616 - val_acc: 0.5283\n",
      "Epoch 9/12\n",
      "422/422 [==============================] - 13s - loss: 0.7741 - acc: 0.6896 - val_loss: 0.7549 - val_acc: 0.6604\n",
      "Epoch 10/12\n",
      "422/422 [==============================] - 14s - loss: 0.7526 - acc: 0.7014 - val_loss: 0.8174 - val_acc: 0.6321\n",
      "Epoch 11/12\n",
      "422/422 [==============================] - 12s - loss: 0.7289 - acc: 0.6706 - val_loss: 0.7354 - val_acc: 0.6604\n",
      "Epoch 12/12\n",
      "422/422 [==============================] - 11s - loss: 0.7950 - acc: 0.6588 - val_loss: 0.7377 - val_acc: 0.6981\n",
      "Train on 337 samples, validate on 85 samples\n",
      "Epoch 1/12\n",
      "337/337 [==============================] - 11s - loss: 0.7196 - acc: 0.7003 - val_loss: 0.7732 - val_acc: 0.6588\n",
      "Epoch 2/12\n",
      "337/337 [==============================] - 9s - loss: 0.6961 - acc: 0.7003 - val_loss: 0.7725 - val_acc: 0.6235\n",
      "Epoch 3/12\n",
      "337/337 [==============================] - 11s - loss: 0.7154 - acc: 0.7240 - val_loss: 0.7605 - val_acc: 0.6588\n",
      "Epoch 4/12\n",
      "337/337 [==============================] - 10s - loss: 0.6569 - acc: 0.7300 - val_loss: 0.7652 - val_acc: 0.6824\n",
      "Epoch 5/12\n",
      "337/337 [==============================] - 12s - loss: 0.6852 - acc: 0.6973 - val_loss: 0.8297 - val_acc: 0.6588\n",
      "Epoch 6/12\n",
      "337/337 [==============================] - 12s - loss: 0.6681 - acc: 0.7151 - val_loss: 0.7649 - val_acc: 0.6235\n",
      "Epoch 7/12\n",
      "337/337 [==============================] - 9s - loss: 0.6506 - acc: 0.7507 - val_loss: 0.7467 - val_acc: 0.6941\n",
      "Epoch 8/12\n",
      "337/337 [==============================] - 10s - loss: 0.6823 - acc: 0.7151 - val_loss: 1.1667 - val_acc: 0.6824\n",
      "Epoch 9/12\n",
      "337/337 [==============================] - 9s - loss: 0.7281 - acc: 0.7181 - val_loss: 0.8572 - val_acc: 0.6471\n",
      "Epoch 10/12\n",
      "337/337 [==============================] - 10s - loss: 0.7002 - acc: 0.7122 - val_loss: 0.7487 - val_acc: 0.6824\n",
      "Epoch 11/12\n",
      "337/337 [==============================] - 12s - loss: 0.6708 - acc: 0.7300 - val_loss: 0.7808 - val_acc: 0.6706\n",
      "Epoch 12/12\n",
      "337/337 [==============================] - 7s - loss: 0.6090 - acc: 0.7389 - val_loss: 0.7718 - val_acc: 0.6706\n",
      "[u'seaborn-darkgrid', u'seaborn-notebook', u'classic', u'seaborn-ticks', u'grayscale', u'bmh', u'seaborn-talk', u'dark_background', u'ggplot', u'fivethirtyeight', u'seaborn-colorblind', u'seaborn-deep', u'seaborn-whitegrid', u'seaborn-bright', u'seaborn-poster', u'seaborn-muted', u'seaborn-paper', u'seaborn-white', u'seaborn-pastel', u'seaborn-dark', u'seaborn-dark-palette']\n",
      "('Test score:', 2.0184556448234701)\n",
      "('Test accuracy:', 0.63207547169811318)\n",
      "4/4 [==============================] - 0s\n",
      "[2 2 2 2]\n",
      "[[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD,RMSprop,adam\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import os\n",
    "import theano\n",
    "from PIL import Image\n",
    "from numpy import *\n",
    "\n",
    "\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 32,32\n",
    "\n",
    "# number of channels\n",
    "img_channels =1\n",
    "\n",
    "\n",
    "#  data\n",
    "\n",
    "path1 = 'C:/Users/dundeva/Documents/CroppedImages'    #path of folder of images    \n",
    "path2 = 'C:/Users/dundeva/Documents/AugmentedImages'  #path of folder to save images    \n",
    "\n",
    "listing = os.listdir(path1) \n",
    "num_samples=size(listing)\n",
    "print num_samples\n",
    "\n",
    "\n",
    "for file in listing:\n",
    "    im = Image.open(path1 + '//' + file)   \n",
    "    img = im.resize((img_rows,img_cols))\n",
    "    gray = img.convert('L')\n",
    "                #need to do some more processing here           \n",
    "    gray.save(path2 +'//' +  file, \"JPEG\")\n",
    "\n",
    "imlist = os.listdir(path1)\n",
    "\n",
    "im1 = array(Image.open('C:/Users/dundeva/Documents/AugmentedImages' + '//'+ imlist[0])) # open one image to get size\n",
    "m,n = im1.shape[0:2] # get the size of the images\n",
    "imnbr = len(imlist) # get the number of images\n",
    "\n",
    "# create matrix to store all flattened images\n",
    "immatrix = array([array(Image.open('C:/Users/dundeva/Documents/AugmentedImages'+ '//' + im2)).flatten()\n",
    "              for im2 in imlist],'f')\n",
    "              \n",
    "label=np.ones((num_samples,),dtype = int)\n",
    "label[0:89]=0\n",
    "label[89:187]=1\n",
    "label[187:]=2\n",
    "\n",
    "\n",
    "data,Label = shuffle(immatrix,label, random_state=2)\n",
    "train_data = [data,Label]\n",
    "\n",
    "#batch_size to train\n",
    "batch_size = 128\n",
    "# number of output classes\n",
    "nb_classes =10\n",
    "# number of epochs to train\n",
    "nb_epoch =12\n",
    "data_augmentation = True\n",
    "\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "nb_pool = 3\n",
    "# convolution kernel size\n",
    "nb_conv = 3\n",
    "\n",
    "(X, y) = (train_data[0],train_data[1])\n",
    "\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n",
    "\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 4, 4, border_mode='same',\n",
    "                        input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32, 4, 4))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "#sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              nb_epoch=nb_epoch,\n",
    "              validation_data=(X_test, Y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "\n",
    "    # this will do preprocessing and realtime data augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied)\n",
    "    datagen.fit(X_train)\n",
    "\n",
    "    # fit the model on the batches generated by datagen.flow()\n",
    "    model.fit_generator(datagen.flow(X_train, Y_train,\n",
    "                        batch_size=batch_size),\n",
    "                        samples_per_epoch=X_train.shape[0],\n",
    "                        nb_epoch=nb_epoch,\n",
    "                        validation_data=(X_test, Y_test))\n",
    "\n",
    "hist = model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "              show_accuracy=True, verbose=1, validation_data=(X_test, Y_test))\n",
    "            \n",
    "            \n",
    "hist = model.fit(X_train, Y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "              show_accuracy=True, verbose=1, validation_split=0.2)\n",
    "\n",
    "\n",
    "# visualizing losses and accuracy\n",
    "\n",
    "train_loss=hist.history['loss']\n",
    "val_loss=hist.history['val_loss']\n",
    "train_acc=hist.history['acc']\n",
    "val_acc=hist.history['val_acc']\n",
    "xc=range(nb_epoch)\n",
    "\n",
    "plt.figure(1,figsize=(7,5))\n",
    "plt.plot(xc,train_loss)\n",
    "plt.plot(xc,val_loss)\n",
    "plt.xlabel('num of Epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.title('train_loss vs val_loss')\n",
    "plt.grid(True)\n",
    "plt.legend(['train','val'])\n",
    "print plt.style.available # use bmh, classic,ggplot for big pictures\n",
    "plt.style.use(['classic'])\n",
    "\n",
    "plt.figure(2,figsize=(7,5))\n",
    "plt.plot(xc,train_acc)\n",
    "plt.plot(xc,val_acc)\n",
    "plt.xlabel('num of Epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('train_acc vs val_acc')\n",
    "plt.grid(True)\n",
    "plt.legend(['train','val'],loc=4)\n",
    "#print plt.style.available # use bmh, classic,ggplot for big pictures\n",
    "plt.style.use(['classic'])\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, show_accuracy=True, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print(model.predict_classes(X_test[1:5]))\n",
    "print(Y_test[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
